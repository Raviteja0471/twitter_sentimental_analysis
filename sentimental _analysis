# Import necessary libraries
from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
import nltk

# Download stopwords (if not already downloaded)
nltk.download('stopwords')

# Training data: movie reviews and sentiment labels
X_train = ["This was really awesome an awesome movie",
           "Great movie! I liked it a lot",
           "Happy Ending! Awesome Acting by hero",
           "loved it!",
           "Bad not up to the mark",
           "Could have been better",
           "Really disappointed by the movie"]

y_train = ["positive", "positive", "positive", "positive", "negative", "negative", "negative"]

# Test data: input sentence for sentiment prediction
X_test = ["it was not good"]

# Tokenizer, stemmer, and stopwords
tokenizer = RegexpTokenizer(r"\w+")
en_stopwords = set(stopwords.words('english'))
ps = PorterStemmer()

# Clean and preprocess the text
def getCleanedText(text):
    text = text.lower()
    tokens = tokenizer.tokenize(text)
    new_tokens = [token for token in tokens if token not in en_stopwords]
    stemmed_tokens = [ps.stem(token) for token in new_tokens]
    clean_text = " ".join(stemmed_tokens)
    return clean_text

X_clean = [getCleanedText(review) for review in X_train]
Xt_clean = [getCleanedText(review) for review in X_test]

# Vectorize the text using CountVectorizer
cv = CountVectorizer(ngram_range=(1, 2))
X_vec = cv.fit_transform(X_clean).toarray()
Xt_vec = cv.transform(Xt_clean).toarray()

# Multinomial Naive Bayes classifier
mn = MultinomialNB()
mn.fit(X_vec, y_train)

# Predict sentiment for the test data
y_pred = mn.predict(Xt_vec)

# Print the predicted sentiment
print("Predicted Sentiment:", y_pred[0])
